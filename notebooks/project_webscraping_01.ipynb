{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec964f9-e1a0-478f-9f9c-16c2cc9961ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importamos la biblioteca 'requests' para realizar solicitudes HTTP\n",
    "import requests  # Permite enviar peticiones HTTP a un servidor\n",
    "\n",
    "# Importamos 'BeautifulSoup' desde 'bs4' para parsear y navegar por el contenido HTML\n",
    "from bs4 import BeautifulSoup  # Facilita la extracción de información de documentos HTML\n",
    "\n",
    "# Importamos 'pandas' para manipular y analizar datos en estructuras de tipo DataFrame\n",
    "import pandas as pd  # Ofrece herramientas para trabajar con datos estructurados\n",
    "\n",
    "# Importamos 'matplotlib.pyplot' para generar gráficos básicos\n",
    "import matplotlib.pyplot as plt  # Permite crear gráficos y visualizaciones\n",
    "\n",
    "# Importamos 'seaborn' para generar visualizaciones estadísticas más avanzadas sobre matplotlib\n",
    "import seaborn as sns  # Ofrece gráficos de mayor calidad y personalización\n",
    "\n",
    "# Configuramos matplotlib para que los gráficos se muestren directamente en el Notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Confirmamos que todas las librerías se han importado correctamente\n",
    "print(\"Librerías importadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777103b-be3a-4921-a8bd-89206a47a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petición exitosa. Código de estado: 200\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: Petición HTTP y obtención del HTML\n",
    "\n",
    "# Definimos la URL base que vamos a scrapear\n",
    "url = \"http://books.toscrape.com/\"\n",
    "\n",
    "# Realizamos la petición GET a la URL para obtener la página HTML\n",
    "response = requests.get(url)  # Envía la solicitud y guarda la respuesta en 'response'\n",
    "\n",
    "# Verificamos el código de estado HTTP para asegurarnos de que la solicitud fue exitosa\n",
    "if response.status_code == 200:  # 200 significa éxito\n",
    "    print(\"Petición exitosa. Código de estado:\", response.status_code)\n",
    "    # Guardamos el contenido HTML en una variable\n",
    "    html_content = response.text  # Extrae el contenido en formato texto (HTML)\n",
    "else:\n",
    "    print(\"Error al realizar la petición. Código de estado:\", response.status_code)\n",
    "    html_content = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434bb0db-4feb-42c7-9f22-d6fb9d2059bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML parseado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Celda 3: Parseo del HTML con BeautifulSoup\n",
    "\n",
    "if html_content:  # Verificamos que haya contenido HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")  # Creamos un objeto BeautifulSoup para parsear\n",
    "    print(\"HTML parseado exitosamente.\")\n",
    "else:\n",
    "    soup = None\n",
    "    print(\"No hay contenido HTML para parsear.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e211ea0e-8b29-402c-a5e4-009aa91c1017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos extraídos correctamente de 20 libros.\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos listas vacías para almacenar la información extraída de cada libro\n",
    "book_titles = []          # Almacenará los títulos de los libros\n",
    "book_prices = []          # Almacenará los precios\n",
    "book_availabilities = []  # Almacenará la información de disponibilidad (ej. 'In stock')\n",
    "book_ratings = []         # Almacenará la calificación (rating) en texto\n",
    "\n",
    "if soup:\n",
    "    # Buscamos todos los elementos <article> con la clase 'product_pod'\n",
    "    book_containers = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    # Iteramos por cada contenedor de libro encontrado\n",
    "    for container in book_containers:\n",
    "        # --- Extracción del título ---\n",
    "        # El título se encuentra en el atributo 'title' de la etiqueta <a> dentro de <h3>\n",
    "        title_tag = container.find(\"h3\").find(\"a\")  # Navega hasta la etiqueta <a>\n",
    "        title = title_tag[\"title\"] if title_tag else \"Título no encontrado\"  # Extrae el título\n",
    "        \n",
    "        # --- Extracción del precio ---\n",
    "        # El precio se halla en una etiqueta <p> con la clase 'price_color'\n",
    "        price_tag = container.find(\"p\", class_=\"price_color\")\n",
    "        price_text = price_tag.text if price_tag else \"0\"  # Extrae el texto del precio\n",
    "        \n",
    "        # Limpiar el texto del precio:\n",
    "        # Se elimina el símbolo de la libra (£) y se elimina el carácter \"Â\" que causa problemas de conversión.\n",
    "        price_text_clean = price_text.replace(\"£\", \"\").replace(\"Â\", \"\").strip()\n",
    "        try:\n",
    "            # Se intenta convertir el precio limpio a un número flotante\n",
    "            price_value = float(price_text_clean)\n",
    "        except ValueError:\n",
    "            # En caso de error, se asigna 0.0 al precio\n",
    "            price_value = 0.0\n",
    "        \n",
    "        # --- Extracción de la disponibilidad ---\n",
    "        # La disponibilidad se encuentra en una etiqueta <p> con la clase 'instock availability'\n",
    "        availability_tag = container.find(\"p\", class_=\"instock availability\")\n",
    "        # Se utiliza .strip() para eliminar espacios y saltos de línea\n",
    "        availability_text = availability_tag.text.strip() if availability_tag else \"No info\"\n",
    "        \n",
    "        # --- Extracción de la calificación (rating) ---\n",
    "        # La calificación se indica en la clase del <p class=\"star-rating X\">\n",
    "        rating_tag = container.find(\"p\", class_=\"star-rating\")\n",
    "        if rating_tag and \"class\" in rating_tag.attrs:\n",
    "            # Se obtienen las clases asignadas, ej: [\"star-rating\", \"Three\"]\n",
    "            rating_classes = rating_tag[\"class\"]\n",
    "            # Se asume que la segunda clase representa la calificación\n",
    "            rating = rating_classes[1] if len(rating_classes) > 1 else \"No rating\"\n",
    "        else:\n",
    "            rating = \"No rating\"\n",
    "        \n",
    "        # Se agregan los datos extraídos a las listas correspondientes\n",
    "        book_titles.append(title)\n",
    "        book_prices.append(price_value)\n",
    "        book_availabilities.append(availability_text)\n",
    "        book_ratings.append(rating)\n",
    "    \n",
    "    print(\"Datos extraídos correctamente de\", len(book_containers), \"libros.\")\n",
    "else:\n",
    "    print(\"No se pudo extraer datos ya que 'soup' es None.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b9e62-e640-499c-9c91-a258dcacf307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
